# -*- coding: utf-8 -*-
"""make_adata.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/pachterlab/BLCSBGLKP_2020/blob/master/notebooks/make_adata.ipynb
"""

!date

"""# Preprocessing FASTQ files into a sample by gene matrix

### Download files and software
"""

!git clone https://github.com/pachterlab/BLCSBGLKP_2020.git
!mkdir temporary

!chmod +x BLCSBGLKP_2020/data/kb/parseSS.py
!BLCSBGLKP_2020/data/kb/parseSS.py < BLCSBGLKP_2020/data/kb/SampleSheet.csv > temporary/metadata.txt
!cat temporary/metadata.txt | awk '{print $1}' > temporary/whitelist.txt

!head -16 BLCSBGLKP_2020/data/kb/SampleSheet.csv

!head -1 temporary/metadata.txt
!head -1 temporary/whitelist.txt

"""### Install kallisto and bustools from GitHub"""

# We need cmake to install kallisto and bustools from source
!apt update
!apt install -y cmake
!apt-get install autoconf

!git clone https://github.com/pachterlab/kallisto.git
!mv kallisto/ temporary/
!cd temporary/kallisto && git checkout covid && mkdir build && cd build && cmake .. && make
!chmod +x temporary/kallisto/build/src/kallisto
!mv temporary/kallisto/build/src/kallisto /usr/local/bin/

!git clone https://github.com/BUStools/bustools.git
!mv bustools/ temporary/
!cd temporary/bustools && git checkout covid && mkdir build && cd build && cmake .. && make
!chmod +x temporary/bustools/build/src/bustools
!mv temporary/bustools/build/src/bustools /usr/local/bin/

!kallisto version
!bustools version

!pip install anndata
!pip install git+https://github.com/pachterlab/kb_python@devel

"""### Make the index"""

!kb ref -k 11 --workflow kite -i temporary/index.idx -g temporary/t2g.txt -f1 temporary/transcriptome.fa BLCSBGLKP_2020/data/kb/kite_11.txt
!rm temporary/index.idx
!printf ">RPP30\nAGATTTGGACCTGCGAGCGGGTTCTGACCTGAAGGCTCTGCGCGGACTTGTGGAGACAGCCGCTC" >> temporary/transcriptome.fa
!printf "RPP30\tRPP30\tRPP30" >> temporary/t2g.txt

!tail temporary/t2g.txt

"""### Download the FASTQs"""

!mkdir temporary/fastqs

!wget --quiet -O temporary/fastqs/Undetermined_S0_L001_I1_001.fastq.gz https://caltech.box.com/shared/static/3i46orxgtwlaho7f9z255hplg6tvfs6h.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L001_R2_001.fastq.gz https://caltech.box.com/shared/static/lh0nyo1v95k1s7nvw4zj84yl6jwx3hpg.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L001_R1_001.fastq.gz https://caltech.box.com/shared/static/0f3h3837xvo2dcqkax67njops5s4zxz0.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L002_I1_001.fastq.gz https://caltech.box.com/shared/static/rxb4h3owka0x2deh0royge4w55u0bub5.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L002_R2_001.fastq.gz https://caltech.box.com/shared/static/2eyqb989cohgv4h00mtjj3lrn3tpgi41.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L002_R1_001.fastq.gz https://caltech.box.com/shared/static/orqpywdlryss9df49tha4i8yywlswrtj.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L003_I1_001.fastq.gz https://caltech.box.com/shared/static/0r5ezocuh9mzxxj6nsf1fgfl38fdbfye.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L003_R2_001.fastq.gz https://caltech.box.com/shared/static/d48e56j9qqxo4sveqiwa3lq9bwzxua4f.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L003_R1_001.fastq.gz https://caltech.box.com/shared/static/7q3xgu2lp2t46638c1rg569duz5kdw9a.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L004_I1_001.fastq.gz https://caltech.box.com/shared/static/pkgyve9ft7u09du66a0e3r4a3ae4mmhc.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L004_R2_001.fastq.gz https://caltech.box.com/shared/static/nvfmriwe1891lfqrvedmoko6i5sd0mm6.gz
!wget --quiet -O temporary/fastqs/Undetermined_S0_L004_R1_001.fastq.gz https://caltech.box.com/shared/static/krcntl56mgt91ca08qvljfhohh9g197m.gz

"""Check the files"""

!zcat temporary/fastqs/Undetermined_S0_L001_I1_001.fastq.gz | awk '(NR-2)%4==0' | head -2
!zcat temporary/fastqs/Undetermined_S0_L001_R2_001.fastq.gz | awk '(NR-2)%4==0' | head -2
!zcat temporary/fastqs/Undetermined_S0_L001_R1_001.fastq.gz | awk '(NR-2)%4==0' | head -2

"""# Processing

### Build the kallisto index
"""

!kallisto index -i temporary/index.idx -k 11 temporary/transcriptome.fa

"""# Align reads to the reference"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # The SwabSeq technology expects the first index, then second, then the biological read. 
# !kallisto bus -x SwabSeq -o temporary/out/ -t 2 -i temporary/index.idx \
# temporary/fastqs/Undetermined_S0_L001_I1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L001_R2_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L001_R1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L002_I1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L002_R2_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L002_R1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L003_I1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L003_R2_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L003_R1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L004_I1_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L004_R2_001.fastq.gz \
# temporary/fastqs/Undetermined_S0_L004_R1_001.fastq.gz

"""### Process the BUS file"""

# sort the BUS file by barcode
!bustools sort -t 2 -m 1G -o temporary/out/sort.bus temporary/out/output.bus
# Correct to the barcodes in the whitelist (obtained from the SampleSheet)
!bustools correct --split -d temporary/out/dump.txt -w temporary/whitelist.txt  -o temporary/out/sort.correct.bus temporary/out/sort.bus
# Sort again to sum the Amplicon counts
!bustools sort -t 2 -m 1G -o temporary/out/sort.correct.sort.bus temporary/out/sort.correct.bus

# bustools count
!mkdir count
!bustools count -o ./count/ -g temporary/t2g.txt -e temporary/out/matrix.ec -t temporary/out/transcripts.txt --cm --genecounts temporary/out/sort.correct.sort.bus

# Write the sorted bus file out for barcode QC
!bustools text -p temporary/out/sort.bus > temporary/out/sort.txt

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import string
import anndata
from collections import defaultdict, OrderedDict
from sklearn.preprocessing import normalize, scale
from sklearn.decomposition import TruncatedSVD

def nd(arr):
    return np.asarray(arr).reshape(-1)

def yex(ax):
    lims = [
        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes
        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes
    ]
    
    # now plot both limits against eachother
    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)
    ax.set_aspect('equal')
    ax.set_xlim(lims)
    ax.set_ylim(lims)
    return ax

fsize=15

plt.rcParams.update({'font.size': fsize})
# %config InlineBackend.figure_format = 'retina'

"""# Load Files

### BUS file into matrix
"""

from kb_python.utils import import_matrix_as_anndata

adata = import_matrix_as_anndata('count/output.mtx', 'count/output.barcodes.txt', 'count/output.genes.txt')

"""### Plate Metadeta (from SampleSheet)"""

# I switch index 1 and index 2 since they are swapped in the BUS file
pmap = pd.read_csv("temporary/metadata.txt", sep="\t", header=None, names=["bcs", "i1", "i2", "plate", "well", "gene", "lysate", "Twist", "ATCC_RNA", "ATCC_viral"], index_col=0)
pmap["bcs"] = pmap["i1"] + pmap["i2"]
pmap.index = pmap["bcs"]
pmap.head()

"""# Filter BUS file and add relevant metadata"""

adata.obs["plate"]      = adata.obs.index.map(pmap["plate"])
adata.obs["well"]       = adata.obs.index.map(pmap["well"])
adata.obs["lysate"]     = adata.obs.index.map(pmap["lysate"])
adata.obs["Twist"]      = adata.obs.index.map(pmap["Twist"])
adata.obs["ATCC_RNA"]   = adata.obs.index.map(pmap["ATCC_RNA"])
adata.obs["ATCC_viral"] = adata.obs.index.map(pmap["ATCC_viral"])

# Drop the barcodes that do not have metadata (keep only ones in the platemap)
#nodup = nodup.loc[nodup["ATCC_RNA"].dropna().index].sort_values("bcs")

adata.obs

adata.obs.eval('plate=="Plate1"')

adata.X

adata.X.todense()[adata.obs.eval('plate=="Plate1"')].sum()

adata.X.todense()[adata.obs.eval('plate=="Plate2"')].sum()

adata.X.sum()

adata.obs["Twist_bool"] = np.logical_and(adata.obs.ATCC_viral.values==0, adata.obs.ATCC_RNA.values==0)
adata.obs["ATCC_viral_bool"] = np.logical_and(adata.obs.Twist.values==0, adata.obs.ATCC_RNA.values==0)
adata.obs["ATCC_RNA_bool"] = np.logical_and(adata.obs.Twist.values==0, adata.obs.ATCC_viral.values==0)

adata.var

"""# Normalize per well (CPM), Log1p, Scale columns"""

adata.X = adata.X.todense()

adata.layers["raw"] = adata.X
scale_num = 1000000
adata.layers["norm"] = normalize(adata.X, norm="l1", axis=1)*scale_num
adata.layers["log1p"] = np.log1p(adata.layers["norm"])
adata.uns = OrderedDict([("log1p", {"base":None})])
adata.X = adata.layers["log1p"]
adata.layers["scale"] = scale(adata.layers["log1p"], axis=0, with_mean=True, with_std=True, copy=True)
adata.X = adata.layers["scale"]

"""# Make PCA"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # PCA
# X = adata.layers["scale"]
# 
# tsvd = TruncatedSVD(n_components=2)
# adata.obsm["X_pca"] = tsvd.fit_transform(X)

fig, ax = plt.subplots(figsize=(7,7))

x = adata.obsm["X_pca"][:,0]
y = adata.obsm["X_pca"][:,1]
c = adata.obs["plate"].astype("category").cat.codes.astype(int)

ax.scatter(x, y, c = c, cmap='nipy_spectral')

ax.set_axis_off()

plt.tight_layout()
plt.show()

"""# Write anndata"""

adata.write("temporary/adata.h5ad")

"""# Barcode QC

We will use the RPP30 gene to check that the whitelist barcode has the top most counts compared to its hamming one distance variants. This is a great QC to ensure that there are no problems with the barcodes. Since the reference contains no shared sequences of 11, each "gene" corresponds to one equivalence class. We will use equivalence class 4 which corresponds to the RPP30 gene.
"""

s = pd.read_csv("temporary/out/sort.txt", header=None, names=["bcs", "umi", "ecs", "cnt"], sep="\t")

s = s[s["ecs"] == 316]

m = pd.read_csv("temporary/out/dump.txt", header=None, names=["old", "new"], sep="\t")

m = m.sort_values("new")

m["plate"]      = m["new"].map(pmap["plate"])
m["plate"]      = m["new"].map(pmap["plate"])
m["well"]       = m["new"].map(pmap["well"])
m["lysate"]     = m["new"].map(pmap["lysate"])
m["gene"]       = m["new"].map(pmap["gene"])
m["Twist"]      = m["new"].map(pmap["Twist"])
m["ATCC_RNA"]   = m["new"].map(pmap["ATCC_RNA"])
m["ATCC_viral"] = m["new"].map(pmap["ATCC_viral"])

m["old_cnt"] = m["old"].map(s.groupby("bcs")["cnt"].sum())
m["new_cnt"] = m["new"].map(s.groupby("bcs")["cnt"].sum())

m = m.dropna(subset=["old_cnt"])

bad = m[m["old_cnt"] > m["new_cnt"]]

"""### We find that many barcodes have less counts than there hamming distance variants"""

bad.new.unique().shape

bad[["old", "new","plate", "well", "lysate", "old_cnt", "new_cnt"]]

"""## An example of an abberant barcode"""

bad[bad["new"] == "AGCCAAGAGAGGGCAT"][["old", "new","plate", "well", "lysate", "old_cnt", "new_cnt"]]

